{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目目标： 实现基于rnn的名字分类器\n",
    "### 总体过程  输入-> 嵌入-> GRU -> 线性层 -> 输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gzip # 打开gz文件的依赖包\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence,pack_sequence,pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建数据类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self,is_train_set = True):\n",
    "        filename = 'names_train.csv.gz' if is_train_set else 'names_test.csv.gz' \n",
    "        with gzip.open(filename, 'rt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "        # 生成人名数据\n",
    "        self.names = [row[0] for row in rows]\n",
    "        self.countries = [row[1] for row in rows]\n",
    "        self.seq_num = len(self.names)\n",
    "        # 生成国家数据\n",
    "        self.country_list = list(sorted(set(self.countries)))\n",
    "        # print(\"zhouyuzhe:   \",self.country_list)\n",
    "        self.country_dict = self.getCountryDict()\n",
    "        self.country_num = len(self.country_list)\n",
    "\n",
    "    \n",
    "    # 生成关于国家的字典  在类方法中  参数必须有self 否则参数会报错的\n",
    "    def getCountryDict(self):\n",
    "        country_dict = dict()\n",
    "        for idx, country_name in enumerate(self.country_list, 0):\n",
    "            country_dict[country_name] = idx\n",
    "        return country_dict\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # 访问list数据  需要使用[]\n",
    "        return self.names[index],self.country_dict[self.countries[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集的长度\n",
    "        return self.seq_num\n",
    "        \n",
    "    def idx2country(self, index):\n",
    "        return self.country_list[index]\n",
    "        \n",
    "    def getCountriesNum(self):\n",
    "        return self.country_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnClassidier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,output_size, n_layers = 1, bidirectional = True):\n",
    "        super(RnnClassidier,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.directional = 2 if bidirectional else 1\n",
    "\n",
    "        # 对词向量进行嵌入\n",
    "        self.embedding = torch.nn.Embedding(input_size,hidden_size)\n",
    "\n",
    "        # 使用gru进行处理\n",
    "        self.Gru = torch.nn.GRU(hidden_size,hidden_size,n_layers,bidirectional= bidirectional)\n",
    "\n",
    "        # 构建全连接网络作为分类器\n",
    "        self.fc = torch.nn.Linear(hidden_size* self.directional,output_size)\n",
    "\n",
    "    # 生成rnn的第一个输入h0\n",
    "    def _init_hidden(self,batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.directional,batch_size,self.hidden_size)\n",
    "        return hidden\n",
    "\n",
    "    # 前向传播\n",
    "    def forward (self, input, seq_lengths):\n",
    "        # 先对input进行转置处理\n",
    "        input = input.t()\n",
    "        # 得到batch_size\n",
    "        batch_size = input.size(1)\n",
    "        # 生成隐藏的维度h0\n",
    "        hidden  = self._init_hidden(batch_size= batch_size)\n",
    "        # 进行词嵌入 \n",
    "        embedding = self.embedding(input)\n",
    "        # 进行padded\n",
    "        gru_inputs = pack_padded_sequence(embedding,seq_lengths)\n",
    "        # 开始使用gru进行计算\n",
    "        output, hidden = self.Gru(gru_inputs, hidden)\n",
    "        # 如果是双向的 拼接\n",
    "        if self.directional == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        # 使用全连接网络预测\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将字符串数据进行转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到字母的ascll码值\n",
    "def name2list(name):\n",
    "    arr = [ord(c) for c in name]\n",
    "    return arr, len(arr)\n",
    "\n",
    "def make_tensors(names, countries):\n",
    "    # 将名字转换成ascll码和名字的长度 list\n",
    "    sequences_and_lengths = [name2list(name) for name in names]\n",
    "    # 拿到名字的ascll码值\n",
    "    name_sequences = [sl[0] for sl in sequences_and_lengths]\n",
    "    # 拿到序列长度\n",
    "    seq_lengths = torch.LongTensor([sl[1] for sl in sequences_and_lengths])\n",
    "    countries = countries.long()\n",
    "    # make tensor of name, BatchSize x SeqLen\n",
    "    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "    # sort by length to use pack_padded_sequence\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "    return seq_tensor, seq_lengths,countries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def trainModel():\n",
    "    total_loss = 0\n",
    "    for i, (names, countries) in enumerate(trainloader, 1):\n",
    "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "        # 使用分类器进行计算\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "        # 正向计算损失\n",
    "        loss = criterion(output, target)\n",
    "        # 优化器梯度归零\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播梯度\n",
    "        loss.backward()\n",
    "        # 执行优化过程\n",
    "        optimizer.step()\n",
    "        # 损失求和\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch} ', end='')\n",
    "            print(f'[{i * len(inputs)}/{len(trainset)}] ', end='')\n",
    "            print(f'loss={total_loss / (i * len(inputs))}')\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型测试模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print(\"evaluating trained model ...\")\n",
    "    # 在利用模型进行测试的时候不需要进行梯度的计算\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(testloader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            percent = '%.2f' % (100 * correct / total)\n",
    "            # print(f'Test set: Accuracy {correct}/{total} {percent}%')\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数的初始化\n",
    "HIDDEN_SIZE = 2\n",
    "BATCH_SIZE = 256\n",
    "N_LAYER = 2\n",
    "N_EPOCHS = 100\n",
    "N_CHARS = 128\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到训练数据\n",
    "trainset = NameDataset(is_train_set=True)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# 根据数据集确定国家数\n",
    "N_COUNTRY = trainset.getCountriesNum()\n",
    "\n",
    "# 加载测试集\n",
    "testset = NameDataset(is_train_set=False)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 初始化模型\n",
    "    classifier = RnnClassidier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER)\n",
    "    # 创建损失函数\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # 创建优化器\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "    # 记录开始时间\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"Training for %d epochs...\" % N_EPOCHS)\n",
    "    acc_list = []\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        # Train cycle\n",
    "        trainModel()\n",
    "        acc = testModel()\n",
    "        acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "epoch = np.arange(1, len(acc_list) + 1, 1)\n",
    "acc_list = np.array(acc_list)\n",
    "plt.plot(epoch, acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 尝试使用分类器进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! putin .  I guess you come from : Russian \n"
     ]
    }
   ],
   "source": [
    "# 处理单个名字\n",
    "def make_data(input_name):\n",
    "    sequences_and_lengths_pre = [name2list(input_name)]\n",
    "    name = [sl[0] for sl in sequences_and_lengths_pre]\n",
    "    seq_lengths = torch.LongTensor([sl[1] for sl in sequences_and_lengths_pre])\n",
    "    seq_tensor = torch.zeros(len(name), seq_lengths.max()).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name, seq_lengths), 0):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "    # sort by length to use pack_padded_sequence\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    return seq_tensor, seq_lengths\n",
    "\n",
    "\n",
    "\n",
    "def guess():\n",
    "    name = input('Please input your name: ')\n",
    "    inputs,sql_len = make_data(name)\n",
    "    # 得到预测\n",
    "    output = classifier(inputs,sql_len)\n",
    "    pred = output.max(dim=1, keepdim=True)[1]\n",
    "\n",
    "    # 进行国家转化\n",
    "    coun = testset.country_list[pred.data.item()]\n",
    "    print('Hi!',name,'.  I guess you come from :',coun,end=' ')\n",
    "    print()\n",
    "\n",
    "\n",
    "guess()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bba41e528b9ae6ac3bca14918216a30fd62a7a5cc8cd4a9b2bafdbd58ed8824d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('dlpython37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
